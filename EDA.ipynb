{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi as wp\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "\n",
    "from src.etl.get_anames import retrieve\n",
    "from src.libcode import txt_to_list, list_to_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enwp = wp.Wikipedia(\"en\")\n",
    "anames = retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dir = \"src/data/init/partisan_phrases/\"\n",
    "pp_txts = os.listdir(pp_dir)\n",
    "score_dict = {}\n",
    "for i in pp_txts:\n",
    "    with open(pp_dir + i) as curtxt:\n",
    "        for line in curtxt.readlines()[1:]:\n",
    "            splt = line.split(\"|\")\n",
    "            score_dict[splt[0]] = float(splt[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_per_text = len(anames)//10\n",
    "# wikitxts_dir = \"src/data/temp/wiki_txts/\"\n",
    "\n",
    "# # If wiki texts folder does not exist make it\n",
    "# if not os.path.exists(wikitxts_dir):\n",
    "#     os.makedirs(wikitxts_dir)\n",
    "\n",
    "# txtlst = []\n",
    "# for ind, aname in enumerate(anames):\n",
    "#     # Get the page text\n",
    "# #     print(ind, aname)\n",
    "#     curpg = enwp.page(aname)\n",
    "#     curtit = curpg.title\n",
    "#     curtxt = curpg.text\n",
    "#     txtlst.append(curtit)\n",
    "#     txtlst.append(curtxt)\n",
    "#     # This ensures it saves into 10 txt files\n",
    "#     if (ind+1) % num_per_text == 0:\n",
    "#         print(ind+1)\n",
    "#         curtxt_name = \"art_pages\" + str((ind+1)//num_per_text) + \".txt\"\n",
    "#         list_to_txt(wikitxts_dir+curtxt_name, txtlst)\n",
    "#         txtlst = []\n",
    "#         time.sleep(10)\n",
    "        \n",
    "# # Save last set of articles\n",
    "# if len(txtlst) > 0:\n",
    "#     curtxt_name = \"art_pages10\" + \".txt\"\n",
    "#     list_to_txt(wikitxts_dir+curtxt_name, txtlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(score_dict.items(), key=lambda item: item[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"stopwords\")\n",
    "\n",
    "stpwrds = stopwords.words(\"english\")\n",
    "porter = stem.PorterStemmer()\n",
    "\n",
    "def string_score(strn, score_dict):\n",
    "    # Lowercase, remove digits and doublespaces\n",
    "    curstr = strn.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    curstr = re.sub(r'[0-9]+', '', curstr)\n",
    "    curstr = re.sub(r'\\n', ' ', curstr)\n",
    "    curstr = re.sub(r'  +', ' ', curstr)\n",
    "    plst = []\n",
    "    for word in curstr.split():\n",
    "        # Check for stopwords\n",
    "        if word not in stpwrds:\n",
    "            \n",
    "#             if len(word) < 4:\n",
    "#                 print(word)\n",
    "            \n",
    "            # Stem the word\n",
    "            pword = porter.stem(word)\n",
    "\n",
    "    #         # Put the stemmed word in the reverse-stemming dictionary\n",
    "    #         if pword not in stem_rev.keys():\n",
    "    #             stem_rev[pword] = [word]\n",
    "    #         elif word not in stem_rev[pword]:\n",
    "    #             stem_rev[pword].append(word)\n",
    "            \n",
    "            plst.append(pword)\n",
    "    curstrlen = len(plst)\n",
    "    curstr = ' '.join(plst)\n",
    "\n",
    "    absscore = 0\n",
    "    sumscore = 0\n",
    "    \n",
    "    counts_dict = {}\n",
    "    \n",
    "    for key, value in score_dict.items():\n",
    "        numoccurs = curstr.count(key)\n",
    "        counts_dict[key] = (numoccurs, value)\n",
    "        curscore = numoccurs*value\n",
    "        absscore += abs(curscore)\n",
    "        sumscore += curscore\n",
    "\n",
    "    counts_dict = sorted(counts_dict.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    return (absscore, sumscore, curstrlen, counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitxts_dir = \"src/data/temp/wiki_txts/\"\n",
    "wiki_txts = [\"art_pages\" + str(i) + \".txt\" for i in range(1,11)]\n",
    "namestat_dict = {}\n",
    "\n",
    "cnt = 0\n",
    "for txt in wiki_txts:\n",
    "    print(0)\n",
    "    txtlst = txt_to_list(wikitxts_dir + txt)\n",
    "    print(len(txtlst))\n",
    "    for item in txtlst:\n",
    "        if cnt % 2 == 0:\n",
    "            print(item)\n",
    "            aname = item\n",
    "        else:\n",
    "            curres = string_score(item,score_dict)\n",
    "            namestat_dict[aname] = curres\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namestat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
