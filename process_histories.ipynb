{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.difflib_bigrams as db\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "import nltk\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from src.etl.get_anames import scrape_anames, retrieve_anames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmls_base = \"src/data/temp/wiki_xmls/\"\n",
    "xmls_list = [x for x in os.listdir(xmls_base) if \".xml\" in x]\n",
    "\n",
    "resdict = {}\n",
    "for fn in xmls_list:\n",
    "    print(fn)\n",
    "    \n",
    "    # This block is for fixing broken xmls with no closing tags\n",
    "    try:\n",
    "        tree = ET.parse(xmls_base + fn)\n",
    "    except Exception as e:\n",
    "        with open(xmls_base + fn, \"a\") as app:\n",
    "            app.write(\"  </page>\")\n",
    "            app.write(\"</mediawiki>\")\n",
    "        tree = ET.parse(xmls_base + fn)\n",
    "        \n",
    "    # Set up the tree and the list of results for the current article\n",
    "    root = tree.getroot().find(\"{http://www.mediawiki.org/xml/export-0.10/}page\")\n",
    "    revlist = []\n",
    "\n",
    "    for rev in root.findall(\"{http://www.mediawiki.org/xml/export-0.10/}revision\"):\n",
    "        # The dictionary for each revision\n",
    "        curdict = {}\n",
    "\n",
    "        curdict[\"time\"] = rev.find(\"{http://www.mediawiki.org/xml/export-0.10/}timestamp\").text\n",
    "        txt = rev.find(\"{http://www.mediawiki.org/xml/export-0.10/}text\").text\n",
    "        \n",
    "        if not txt is None:\n",
    "            curdict[\"text\"] = txt\n",
    "        else:\n",
    "            curdict[\"text\"] = \"\"\n",
    "            \n",
    "        comm = rev.find(\"{http://www.mediawiki.org/xml/export-0.10/}comment\")\n",
    "        if not comm is None:\n",
    "            curdict[\"comm\"] = comm.text\n",
    "        else:\n",
    "            curdict[\"comm\"] = \"\"\n",
    "\n",
    "        cont = rev.find(\"{http://www.mediawiki.org/xml/export-0.10/}contributor\")\n",
    "        user = cont.find(\"{http://www.mediawiki.org/xml/export-0.10/}username\")\n",
    "        if not user is None:\n",
    "            curdict[\"user\"] = user.text\n",
    "        else:\n",
    "            curdict[\"user\"] = cont.find(\"{http://www.mediawiki.org/xml/export-0.10/}ip\").text\n",
    "\n",
    "        revlist.append(curdict)\n",
    "        \n",
    "    resdict[fn[:-4]] = revlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, revl in resdict.items():\n",
    "    print(name)\n",
    "    print(revl[0][\"time\"],revl[-1][\"time\"])\n",
    "    print(len(revl))\n",
    "    print(\"________________\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "\n",
    "if test:\n",
    "    pp_dir = \"test/partisan_phrases/\"\n",
    "else:\n",
    "    pp_dir = \"src/data/init/partisan_phrases/\"\n",
    "    \n",
    "pp_txts = os.listdir(pp_dir)\n",
    "score_dict = {}\n",
    "for i in pp_txts:\n",
    "    with open(pp_dir + i) as curtxt:\n",
    "        print(len(curtxt.readlines()))\n",
    "        for line in curtxt.readlines()[1:]:\n",
    "            splt = line.split(\"|\")\n",
    "            score_dict[splt[0]] = float(splt[1].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# Populate resdict with stats\n",
    "for name, revl in resdict.items():\n",
    "    prevr = db.bigram(preproc_strn(revl[0][\"text\"])[0])\n",
    "    for rev in revl:\n",
    "        if cnt % 1000 == 1:\n",
    "            print(cnt)\n",
    "        cnt += 1\n",
    "        curr = db.bigram(preproc_strn(rev[\"text\"])[0])\n",
    "        diffs = db.unique_items(prevr, curr)\n",
    "        rem, add = diffs\n",
    "        \n",
    "        # Trying to get the following output: [absscore, sumscore, numwords, counts_list, totphrs]\n",
    "        rem_abs = 0\n",
    "        add_abs = 0\n",
    "        rem_sum = 0\n",
    "        add_sum = 0\n",
    "        rem_num = len(rem)\n",
    "        add_num = len(add)\n",
    "#         add_counts = {}\n",
    "#         rem_counts = {}\n",
    "        add_phrs = 0\n",
    "        rem_phrs = 0\n",
    "        \n",
    "        for bigr in rem:\n",
    "            if bigr in score_dict.keys():\n",
    "                rem_abs += abs(score_dict[bigr])\n",
    "                rem_sum += score_dict[bigr]\n",
    "                rem_phrs += 1\n",
    "                \n",
    "        for bigr in add:  \n",
    "            if bigr in score_dict.keys():\n",
    "                add_abs += abs(score_dict[bigr])\n",
    "                add_sum += score_dict[bigr]\n",
    "                add_phrs += 1\n",
    "        \n",
    "        rev[\"rem\"] = rem\n",
    "        rev[\"add\"] = add\n",
    "        rev[\"rem_abs\"] = rem_abs\n",
    "        rev[\"add_abs\"] = add_abs\n",
    "        rev[\"rem_sum\"] = rem_sum\n",
    "        rev[\"add_sum\"] = add_sum\n",
    "        rev[\"rem_num\"] = rem_num\n",
    "        rev[\"add_num\"] = add_num\n",
    "        rev[\"rem_phrs\"] = rem_phrs\n",
    "        rev[\"add_phrs\"] = add_phrs\n",
    "        \n",
    "        del rev[\"text\"]\n",
    "        prevr = curr\n",
    "            \n",
    "\n",
    "# [absscore, sumscore, numwords, counts_list, totphrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biascnt = 0\n",
    "cnt = 0\n",
    "for name, revl in resdict.items():\n",
    "    for rev in revl:\n",
    "        cnt += 1\n",
    "        if \"bias\" or \"ideol\" in rev[\"comm\"].lower():\n",
    "            print(rev[\"comm\"])\n",
    "            biascnt += 1\n",
    "biascnt / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "rd_base = \"src/data/temp/resdicts/\"\n",
    "with open(rd_base + \"rd.json\", \"w\") as outfile:  \n",
    "    json.dump(resdict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
